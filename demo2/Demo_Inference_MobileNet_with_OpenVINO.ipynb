{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO使ってMobileNetモデルを推論するデモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まずはオリジナルのモデル（Keras + Tensorflow）の推論用関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras import models\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def inference_original(total = 100):\n",
    "    model = models.load_model('top_layers.mn.hdf5')\n",
    "    \n",
    "    #Read in Labels\n",
    "    arg_labels=\"mn-labels.txt\"\n",
    "    label_file = open(arg_labels, \"r\")\n",
    "    labels = label_file.read().split('\\n')\n",
    "    \n",
    "    list_df = pd.DataFrame( columns=['正解ラベル','予測ラベル','全処理時間(msec)','推論時間(msec)'] )\n",
    "\n",
    "    total_spent_time = 0\n",
    "    total_infer_spent_time = 0\n",
    "    \n",
    "    print(str(total) + '枚の画像を処理中．．．')\n",
    "    for i in range(total):\n",
    "        time1 = time.time()\n",
    "        file_list = glob.glob(\"test/*/*\")\n",
    "        img_path = random.choice(file_list)\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        time2 = time.time()\n",
    "        preds = model.predict(x)\n",
    "        \n",
    "        infer_spent_time = time.time() - time2\n",
    "        total_infer_spent_time += infer_spent_time\n",
    "        \n",
    "        spent_time = time.time() - time1\n",
    "        total_spent_time += spent_time\n",
    "        \n",
    "        top = preds[0].argsort()[-1:][::-1]\n",
    "        pred_label = labels[top[0]]\n",
    "        print(\"*\", end=\"\")\n",
    "        #print(str(i + 1) + '枚目: 正解=' + img_cat + '、予測=' + pred_label + '、全処理時間=' + str(int(spent_time * 1000)) + 'msec、推論時間=' + str(int(infer_spent_time * 1000)) + ' msec')\n",
    "        #print(\"Raw Predictions: \", preds[0])\n",
    "        tmp_se = pd.Series( [img_cat, pred_label, str(int(spent_time * 1000)), str(int(infer_spent_time * 1000)) ], index=list_df.columns )\n",
    "        list_df = list_df.append( tmp_se, ignore_index=True )        \n",
    "\n",
    "    print()\n",
    "    print('完了！')\n",
    "    print()\n",
    "    print(\"平均処理時間: \" + str(int((total_spent_time / total)*1000.0)) + \" ms/枚\")\n",
    "    print(\"平均推論時間: \" + str(int((total_infer_spent_time / total)*1000.0)) + \" ms/枚\")\n",
    "    display(list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 続いて、オリジナルのモデルをOpenVINOのIR形式に変換\n",
    "\n",
    "OpenVINOに付属しているModel Optimizerを用います。\n",
    "大前提として、OSの環境変数に下記がセットされている必要があります。\n",
    "\n",
    "PYTHONPATH=c:\\Program Files (x86)\\IntelSWTools\\openvino\\python\\python3.6;c:\\Program Files (x86)\\IntelSWTools\\openvino\\python\\python3;\n",
    "\n",
    "より詳しい説明は下記URLをご覧ください。 https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Converting_Model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"c:\\Program Files (x86)\\IntelSWTools\\openvino\\deployment_tools\\model_optimizer\\mo.py\" --input_model=tf_model\\top_layers.mn.pb --input_shape=[1,224,224,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルが正常に変換されると、xmlファイルとbinファイルが出来上がります。これがOpenVINOで用いられるIR形式のモデルの実体です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここで、IR形式のモデルを推論処理するための関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras import models\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "def inference_openvino(total = 100, target_device=\"CPU\"):\n",
    "    model_xml = 'top_layers.mn.xml'\n",
    "    model_bin = 'top_layers.mn.bin'\n",
    "\n",
    "    # Plugin initialization for specified device and load extensions library if specified\n",
    "    ie = IEPlugin(device=target_device, plugin_dirs='')\n",
    "\n",
    "    # Read IR\n",
    "    net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    net.batch_size = 1\n",
    "\n",
    "    # Loading model to the plugin\n",
    "    exec_net = ie.load(network=net)\n",
    "    \n",
    "    #Read in Labels\n",
    "    arg_labels=\"mn-labels.txt\"\n",
    "    label_file = open(arg_labels, \"r\")\n",
    "    labels = label_file.read().split('\\n')\n",
    "    \n",
    "    list_df = pd.DataFrame( columns=['正解ラベル','予測ラベル','全処理時間(msec)','推論時間(msec)'] )\n",
    "\n",
    "    total_spent_time = 0\n",
    "    total_infer_spent_time = 0\n",
    "    \n",
    "    print(str(total) + '枚の画像を処理中．．．')\n",
    "    for j in range(total):\n",
    "        time1 = time.time()\n",
    "        file_list = glob.glob(\"test/*/*\")\n",
    "        img_path = random.choice(file_list)\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "        # Read and pre-process input images\n",
    "        n, c, h, w = net.inputs[input_blob].shape\n",
    "        images = np.ndarray(shape=(n, c, h, w))\n",
    "        for i in range(n):\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            if image.shape[:-1] != (h, w):\n",
    "                image = cv2.resize(image, (w, h))\n",
    "            image = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "            image = image.reshape((n, c, h, w))\n",
    "            image = preprocess_input(image)\n",
    "            images[i] = image\n",
    "\n",
    "        # Start sync inference\n",
    "        time2 = time.time()\n",
    "        preds = exec_net.infer(inputs={input_blob: images})\n",
    "        \n",
    "        infer_spent_time = time.time() - time2\n",
    "        total_infer_spent_time += infer_spent_time\n",
    "        \n",
    "        spent_time = time.time() - time1\n",
    "        total_spent_time += spent_time\n",
    "        \n",
    "        preds = preds[out_blob]\n",
    "        top = preds[0].argsort()[-1:][::-1]\n",
    "        pred_label = labels[top[0]]\n",
    "        print(\"*\", end=\"\")\n",
    "        #print(str(j + 1) + '枚目: 正解=' + img_cat + '、予測=' + pred_label + '、全処理時間=' + str(int(spent_time * 1000)) + 'msec、推論時間=' + str(int(infer_spent_time * 1000)) + ' msec')\n",
    "        #print(\"Raw Predictions: \", preds)\n",
    "        tmp_se = pd.Series( [img_cat, pred_label, str(int(spent_time * 1000)), str(int(infer_spent_time * 1000)) ], index=list_df.columns )\n",
    "        list_df = list_df.append( tmp_se, ignore_index=True ) \n",
    "\n",
    "    print()\n",
    "    print('完了！')\n",
    "    print()\n",
    "    print(\"平均処理時間: \" + str(int((total_spent_time / total)*1000.0)) + \" ms/枚\")\n",
    "    print(\"平均推論時間: \" + str(int((total_infer_spent_time / total)*1000.0)) + \" ms/枚\")\n",
    "    display(list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## では、2つの関数を実行して性能を比較しましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まずは、オリジナルのモデルから実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_original(total=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 続いて、OpenVINOのIR形式のモデルを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_openvino(total=50, target_device=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同じIR形式のモデルを内臓GPUに推論処理をオフロードして実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_openvino(total=50, target_device=\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## いかがでしたでしょうか？\n",
    "## これより下は、この2つのモデルを用いた動画データに対する推論性能の比較です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO Video Inference on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 Intel Corporation.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining\n",
    "a copy of this software and associated documentation files (the\n",
    "\"Software\"), to deal in the Software without restriction, including\n",
    "without limitation the rights to use, copy, modify, merge, publish,\n",
    "distribute, sublicense, and/or sell copies of the Software, and to\n",
    "permit persons to whom the Software is furnished to do so, subject to\n",
    "the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be\n",
    "included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    "LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    "WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective \n",
    "Transform your frozen graph into an intermediate representation (.bin/.xml) needed to use with OpenVINO then instantiate your OpenVINO model and inference live on a video file.\n",
    "\n",
    "# Activities \n",
    "**In this section of the training you will**\n",
    "- Understand OpenVINO Arguments\n",
    "- Instantiate OpenVINO Network\n",
    "- Use OpenCV to read video and pass frames to OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import IPython.display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Network\n",
    "\n",
    "Next, we'll instantiate our network.  If you want to take a closer look at all the specific steps required to instantitate the network look at the inference.py file included in this directory.  Instead, we're going to look at the parameters passed to the constructor.  We see the .XML file passed as the base model, no CPU extensions and targeting the CPU as the device type.\n",
    "\n",
    "Then we'll call out to the constructor for the Network instantiation. We then want to load our model into that network by passing in the above parameters to load_model. Lastly, we'll read in our labels file that we're going to use to decode the results during our inference.\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import Network\n",
    "import sys\n",
    "\n",
    "arg_model=\"top_layers.mn.xml\"\n",
    "arg_cpu_extension=None\n",
    "arg_device=\"GPU\"\n",
    "\n",
    "# Initialise the class\n",
    "infer_network = Network()\n",
    "# Load the network to IE plugin to get shape of input layer\n",
    "plugin, (n_fd, c_fd, h_fd, w_fd) = infer_network.load_model(arg_model, arg_device, 1, 1, 0, arg_cpu_extension)\n",
    "\n",
    "#Read in Labels\n",
    "arg_labels=\"mn-labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the inference!  There are 8 steps that we're doing in the code below:\n",
    "- Start a video or webcam capture\n",
    "- Read the video frame\n",
    "- Put the classification text on to the frame\n",
    "- Render the frame to the Cell output field\n",
    "- Resize/Transpose/Reshape/Preprocess frame\n",
    "- Start an inference request\n",
    "- Interpret the inference result\n",
    "- Clear frame from notebook cell\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import preprocess_input\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(\"persian.mp4\")\n",
    "pred_label = \"\"\n",
    "fps = 0\n",
    "ips = 0\n",
    "while True:\n",
    "    time1 = time.time()\n",
    "    ret, next_frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        next_frame = cv2.cvtColor(next_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        cv2.putText(next_frame,str(pred_label) + \" \" + str(fps) + \"fps \" + str(ips) + \"ips\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(next_frame,str(pred_label) + \" \" + str(fps) + \"fps \" + str(ips) + \"ips\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(next_frame).save(f, 'jpeg')\n",
    "        IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "        in_frame_fd = cv2.resize(next_frame, (w_fd, h_fd))\n",
    "        in_frame_fd = in_frame_fd.transpose((2, 0, 1))\n",
    "        in_frame_fd = in_frame_fd.reshape((n_fd, c_fd, h_fd, w_fd))\n",
    "        in_frame_fd = preprocess_input(in_frame_fd)\n",
    "\n",
    "        time3 = time.time()\n",
    "        # Start asynchronous inference for specified request\n",
    "        infer_network.exec_net(0, in_frame_fd)\n",
    "        # Wait for the result\n",
    "        infer_network.wait(0)\n",
    "        # Results of the output layer of the network\n",
    "        res = infer_network.get_output(0)\n",
    "        time4 = time.time()\n",
    "\n",
    "        top = res[0].argsort()[-1:][::-1]\n",
    "        pred_label = labels[top[0]]\n",
    "\n",
    "        time2 = time.time()\n",
    "        fps = '%.1f' % (1/(time2-time1))\n",
    "        ips = '%.1f' % (1/(time4-time3))\n",
    "\n",
    "        clear_output(wait=True)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"Video Ended\")\n",
    "infer_network.clean()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the case that Original model is used for the same video data. You probably can see the difference of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import preprocess_input\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras import models\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "\n",
    "model = models.load_model('top_layers.mn.hdf5')\n",
    "\n",
    "cap = cv2.VideoCapture(\"persian.mp4\")\n",
    "pred_label = \"\"\n",
    "fps = 0\n",
    "ips = 0\n",
    "while True:\n",
    "    time1 = time.time()\n",
    "    ret, next_frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        next_frame = cv2.cvtColor(next_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        cv2.putText(next_frame,str(pred_label) + \" \" + str(fps) + \"fps \" + str(ips) + \"ips\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(next_frame,str(pred_label) + \" \" + str(fps) + \"fps \" + str(ips) + \"ips\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(next_frame).save(f, 'jpeg')\n",
    "        IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "        in_frame_fd = cv2.resize(next_frame, (w_fd, h_fd))\n",
    "        #in_frame_fd = in_frame_fd.transpose((2, 0, 1))\n",
    "        in_frame_fd = in_frame_fd.reshape((n_fd, h_fd, w_fd, c_fd))\n",
    "        in_frame_fd = preprocess_input(in_frame_fd)\n",
    "\n",
    "        time3 = time.time()\n",
    "        # Start inference for specified request\n",
    "        res = model.predict(in_frame_fd)\n",
    "        time4 = time.time()\n",
    "\n",
    "        top = res[0].argsort()[-1:][::-1]\n",
    "        pred_label = labels[top[0]]\n",
    "\n",
    "        time2 = time.time()\n",
    "        fps = '%.1f' % (1/(time2-time1))\n",
    "        ips = '%.1f' % (1/(time4-time3))\n",
    "\n",
    "        clear_output(wait=True)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"Video Ended\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    " \n",
    "**In this section of the training you learned**\n",
    "- Create Intermediate Representation (.bin/.xml)\n",
    "- Understand OpenVINO Arguments\n",
    "- Instantiate OpenVINO Network\n",
    "- Use OpenCV to read video and pass frames to OpenVINO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
