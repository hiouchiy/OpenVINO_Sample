{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "- Install OpenVINO (Tested 2019R3.1 on this notebook)\n",
    "- Install Intel-PyTorch following [here](https://software.intel.com/en-us/articles/getting-started-with-intel-optimization-of-pytorch)\n",
    "- Clone [this repository](https://github.com/taneishi/CheXNet)\n",
    "- Put this notebook into the root folder of the cloned repository as above.\n",
    "- Download a dataset from [here](https://nihcc.app.box.com/v/ChestXray-NIHCC) and unzip it and put them into \"ChestX-ray14/images\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export a ONNX\n",
    "First, we need to export the model as a ONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main CheXNet model implementation.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from read_data import ChestXrayDataSet\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import timeit\n",
    "\n",
    "CKPT_PATH = './model.pth.tar'\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "DATA_DIR = './ChestX-ray14/images'\n",
    "TEST_IMAGE_LIST = './ChestX-ray14/labels/test_list.txt'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def export_onnx():\n",
    "    #cudnn.benchmark = True\n",
    "\n",
    "    #torch.cuda.set_enabled_lms(True) \n",
    "    #print('LMS is %s' % ('On' if torch.cuda.get_enabled_lms() else 'Off'))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    \n",
    "    # initialize and load the model\n",
    "    model = DenseNet121(N_CLASSES).to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "\n",
    "    if os.path.isfile(CKPT_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_PATH, map_location=device)\n",
    "        state_dict = {}\n",
    "        for k,v in checkpoint['state_dict'].items():\n",
    "            k = k.replace('module.', '')\n",
    "            k = k.replace('norm.1', 'norm1')\n",
    "            k = k.replace('norm.2', 'norm2')\n",
    "            k = k.replace('conv.1', 'conv1')\n",
    "            k = k.replace('conv.2', 'conv2')\n",
    "            state_dict[k] = v\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"=> loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no model found\")\n",
    "\n",
    "\n",
    "    model.train(False)\n",
    "    dummy_input = torch.randn(BATCH_SIZE,3,224,224)\n",
    "    torch_out = model(dummy_input)\n",
    "    torch.onnx.export(model,\n",
    "                      dummy_input, \n",
    "                      'densenet121.onnx',\n",
    "                      export_params=True,\n",
    "                      do_constant_folding= True,\n",
    "                      input_names=['input'],\n",
    "                      output_names=['output'],\n",
    "                      dynamic_axes={'input': {0 : 'batch_size'},\n",
    "                                    'output': {0: 'batch_size'}},\n",
    "                      verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "class DenseNet121(nn.Module):\n",
    "    \"\"\"Model modified.\n",
    "\n",
    "    The architecture of our model is the same as standard DenseNet121\n",
    "    except the classifier layer which has an additional sigmoid function.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, out_size):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_onnx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run OpenVINO's Model Optimizer\n",
    "Then, we can run MO to convert the ONNX to IR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /opt/intel/openvino/deployment_tools/model_optimizer/mo_onnx.py --input_model=densenet121.onnx --data_type=FP32 --batch=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create annotation data\n",
    "Then, we need to create annotation file for calibration. Since we use the original dataset here, custom conversion script is needed. Ypu can download the script from [here](annotation.py)\n",
    "\n",
    "Note: Maybe you should install some additional libraries as below.\n",
    "- yamlloader\n",
    "- nibabel \n",
    "- tqdm\n",
    "- Shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to store annotation file is going to be created here.\n",
    "!mkdir annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python annotation.py chest_xray --annotation_file ChestX-ray14/labels/val_list.txt -ss 200 -o annotations -a chestx.pickle -m chestx.json --data_dir ChestX-ray14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run OpenVINO's Calibrator\n",
    "Then, we can run the calibrator. Also we run custome caribration script here because custom adapter is needed.\n",
    "\n",
    "Note: Maybe you should install some additional libraries as below.\n",
    "- xmltodict\n",
    "- progress \n",
    "- py-cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This command may not work fine on Notebook. If so, you can run this on command line.\n",
    "!python calibrate.py --config chestx.yml -d def.yml -M /opt/intel/openvino/deployment_tools/model_optimizer --models . --annotations annotations --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference (SYNC mode)\n",
    "Finally, we can execute inference with the INT8 model. This is syncronized mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main CheXNet model implementation.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import timeit\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from read_data import ChestXrayDataSet\n",
    "\n",
    "\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "DATA_DIR = './ChestX-ray14/images'\n",
    "TEST_IMAGE_LIST = './ChestX-ray14/labels/test_list.txt'\n",
    "BATCH_SIZE = 32\n",
    "N_CROPS = 10\n",
    "\n",
    "\n",
    "def crop(img, top, left, height, width):\n",
    "    return img.crop((left,top, left+width, top+height))\n",
    "\n",
    "def five_crop(img, size):\n",
    "    image_width, image_height = img.width\n",
    "    crop_heigh, crop_width = size\n",
    "    tl = img.crop((0,0, crop_width, crop_height))\n",
    "    tr = img.crop((image_width - crop_width, 0, image_width, crop_height))\n",
    "    return (tl, tr)\n",
    "    \n",
    "def run_sync():\n",
    "    model_xml = \"densenet121_i8.xml\"\n",
    "    model_bin = os.path.splitext(model_xml)[0]+\".bin\"\n",
    "\n",
    "    log.info(\"Creating Inference Engine\")\n",
    "    ie = IECore()\n",
    "    net = IENetwork(model=model_xml, weights=model_bin)\n",
    "    log.info(\"Preparing input blobs\")\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    net.batch_size = (BATCH_SIZE*N_CROPS)\n",
    "\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "\n",
    "\n",
    "    # for image load\n",
    "    # test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "    #                                 image_list_file=TEST_IMAGE_LIST,\n",
    "    #                                 transform=transforms.Compose([\n",
    "    #                                     transforms.Resize(256),\n",
    "    #                                     transforms.TenCrop(224),\n",
    "    #                                     transforms.Lambda\n",
    "    #                                     (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))]))\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "    test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=TEST_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.TenCrop(224),\n",
    "                                        transforms.Lambda\n",
    "                                        (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                                        transforms.Lambda\n",
    "                                        (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                                    ]))\n",
    "    \n",
    "    print(test_dataset)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, num_workers=10, pin_memory=False)\n",
    "\n",
    "    gt = torch.FloatTensor()\n",
    "    pred = torch.FloatTensor()\n",
    "    \n",
    "    # images = np.ndarray(shape=(n,c,h,w))\n",
    "\n",
    "    #loading model to the plugin\n",
    "    log.info(\"Loading model to the plugin\")\n",
    "    #exec_net = ie.load_network(network=net, device_name=\"CPU\", config={'DYN_BATCH_ENABLED': 'YES'})\n",
    "    exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "\n",
    "    \n",
    "    now = timeit.default_timer()\n",
    "    for i , (inp, target) in enumerate(test_loader):\n",
    "        gt = torch.cat((gt, target), 0)\n",
    "        bs, n_crops, c, h, w = inp.size()\n",
    "        images = inp.view(-1, c, h, w).numpy()\n",
    "        # print(images.shape)\n",
    "        # print(bs)\n",
    "        if bs !=  BATCH_SIZE:\n",
    "            images2 = np.zeros(shape=(BATCH_SIZE* n_crops, c, h, w))\n",
    "            images2[:bs*n_crops, :c, :h, :w] = images\n",
    "            images = images2\n",
    "        res = exec_net.infer(inputs={input_blob: images})\n",
    "        res = res[out_blob]\n",
    "        res = res.reshape(BATCH_SIZE, n_crops,-1)\n",
    "        #print(res)\n",
    "        res = np.mean(res, axis=1)\n",
    "        if bs != BATCH_SIZE:\n",
    "            #print(res.shape)\n",
    "            res = res[:bs, :res.shape[1]]\n",
    "        #print(res)\n",
    "        pred = torch.cat((pred, torch.from_numpy(res)), 0)\n",
    "        #print(res.shape)\n",
    "        \n",
    "    print('Elapsed time: %0.2f sec.' % (timeit.default_timer() - now))\n",
    "\n",
    "    AUROCs = compute_AUCs(gt, pred)\n",
    "    AUROC_avg = np.array(AUROCs).mean()\n",
    "    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {:.3f}'.format(CLASS_NAMES[i], AUROCs[i]))\n",
    "\n",
    "def roc_auc_score_FIXED(y_true, y_pred):\n",
    "    if len(np.unique(y_true)) == 1:\n",
    "        return accuracy_score(y_true, np.rint(y_pred))\n",
    "    return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        \n",
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score_FIXED(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference (ASYNC mode)\n",
    "This is asynchronized mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main CheXNet model implementation.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import timeit\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from read_data import ChestXrayDataSet\n",
    "\n",
    "# for async\n",
    "#from openvino.tools.benchmark.utils.infer_request_wrap import InferRequestsQueue\n",
    "# copy code from the file\n",
    "from datetime import datetime\n",
    "import threading\n",
    "\n",
    "\n",
    "class InferReqWrap:\n",
    "    def __init__(self, request, req_id, callback_queue, out_blob):\n",
    "        self.req_id = req_id\n",
    "        self.request = request\n",
    "        self.request.set_completion_callback(self.callback, self.req_id)\n",
    "        self.callbackQueue = callback_queue\n",
    "        self.__ground_truth = torch.FloatTensor()\n",
    "        self.__pred = torch.FloatTensor()\n",
    "        self.out_blob = out_blob\n",
    "\n",
    "    def callback(self, status_code, user_data):\n",
    "        if user_data != self.req_id:\n",
    "            print('Request ID {} does not correspond to user data {}'.format(self.req_id, user_data))\n",
    "        elif status_code:\n",
    "            print('Request {} failed with status code {}'.format(self.req_id, status_code))\n",
    "        res = self.request.outputs[self.out_blob]\n",
    "        res = res.reshape(BATCH_SIZE, N_CROPS, -1)\n",
    "        res = np.mean(res, axis = 1)\n",
    "        if self.__bs != BATCH_SIZE:\n",
    "            res = res[:self.__bs, :res.shape[1]]\n",
    "        self.__pred = torch.cat((self.__pred, torch.from_numpy(res)), 0)\n",
    "        self.callbackQueue(self.req_id, self.request.latency)\n",
    "\n",
    "    def start_async(self, input_data, bs, ground_truth=None):\n",
    "        self.__ground_truth=torch.cat((self.__ground_truth, ground_truth), 0)\n",
    "        self.__bs = bs\n",
    "        self.request.async_infer(input_data)\n",
    "\n",
    "    def infer(self, input_data, ground_truth=None):\n",
    "        self.request.infer(input_data)\n",
    "        self.callbackQueue(self.req_id, self.request.latency)\n",
    "\n",
    "    def get_ground_truth(self):\n",
    "        return self.__ground_truth\n",
    "\n",
    "    def get_prediction(self):\n",
    "        return self.__pred\n",
    "\n",
    "\n",
    "class InferRequestsQueue:\n",
    "    def __init__(self, requests, out_blob):\n",
    "        self.idleIds = []\n",
    "        self.requests = []\n",
    "        self.times = []\n",
    "        for req_id in range(len(requests)):\n",
    "            self.requests.append(InferReqWrap(requests[req_id], req_id, self.put_idle_request, out_blob))\n",
    "            self.idleIds.append(req_id)\n",
    "        self.startTime = datetime.max\n",
    "        self.endTime = datetime.min\n",
    "        self.cv = threading.Condition()\n",
    "\n",
    "    def reset_times(self):\n",
    "        self.times.clear()\n",
    "\n",
    "    def get_duration_in_seconds(self):\n",
    "        return (self.endTime - self.startTime).total_seconds()\n",
    "\n",
    "    def put_idle_request(self, req_id, latency):\n",
    "        self.cv.acquire()\n",
    "        self.times.append(latency)\n",
    "        self.idleIds.append(req_id)\n",
    "        self.endTime = max(self.endTime, datetime.now())\n",
    "        self.cv.notify()\n",
    "        self.cv.release()\n",
    "\n",
    "    def get_idle_request(self):\n",
    "        self.cv.acquire()\n",
    "        while len(self.idleIds) == 0:\n",
    "            self.cv.wait()\n",
    "        req_id = self.idleIds.pop()\n",
    "        self.startTime = min(datetime.now(), self.startTime)\n",
    "        self.cv.release()\n",
    "        return self.requests[req_id]\n",
    "\n",
    "    def wait_all(self):\n",
    "        self.cv.acquire()\n",
    "        while len(self.idleIds) != len(self.requests):\n",
    "            self.cv.wait()\n",
    "        self.cv.release()\n",
    "\n",
    "\n",
    "\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "DATA_DIR = './ChestX-ray14/images'\n",
    "TEST_IMAGE_LIST = './ChestX-ray14/labels/test_list.txt'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "N_CROPS = 10\n",
    "NUM_REQUESTS=8\n",
    "\n",
    "def run_async():\n",
    "    model_xml = \"densenet121_i8.xml\"\n",
    "    model_bin = os.path.splitext(model_xml)[0]+\".bin\"\n",
    "\n",
    "    log.info(\"Creating Inference Engine\")\n",
    "    ie = IECore()\n",
    "    net = IENetwork(model=model_xml, weights=model_bin)\n",
    "    log.info(\"Preparing input blobs\")\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    net.batch_size = (BATCH_SIZE*N_CROPS)\n",
    "\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "    test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=TEST_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.TenCrop(224),\n",
    "                                        transforms.Lambda\n",
    "                                        (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                                        transforms.Lambda\n",
    "                                        (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                                    ]))\n",
    "    \n",
    "    print(test_dataset)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, num_workers=10, pin_memory=False)\n",
    "\n",
    "    gt = torch.FloatTensor()\n",
    "    pred = torch.FloatTensor()\n",
    "    \n",
    "    #loading model to the plugin\n",
    "    log.info(\"Loading model to the plugin\")\n",
    "    #exec_net = ie.load_network(network=net, device_name=\"CPU\", config={'DYN_BATCH_ENABLED': 'YES'})\n",
    "\n",
    "    #config = {\"CPU_THREADS_NUM\": \"48\", \"CPU_THROUGHPUT_STREAMS\": \"CPU_THROUGHPUT_AUTO\"}\n",
    "    config = {\"CPU_THROUGHPUT_STREAMS\": \"8\"}\n",
    "    exec_net = ie.load_network(network=net, device_name=\"CPU\", config=config, num_requests=NUM_REQUESTS)\n",
    "    # Number of requests\n",
    "    infer_requests = exec_net.requests\n",
    "    print(\"reqeuest len\", len(infer_requests))\n",
    "    request_queue = InferRequestsQueue(infer_requests, out_blob)\n",
    "\n",
    "    now = timeit.default_timer()\n",
    "    for i , (inp, target) in enumerate(test_loader):\n",
    "        # gt = torch.cat((gt, target), 0)\n",
    "        bs, n_crops, c, h, w = inp.size()\n",
    "        images = inp.view(-1, c, h, w).numpy()\n",
    "        #print(images.shape)\n",
    "        #print(bs)\n",
    "        if bs !=  BATCH_SIZE:\n",
    "            images2 = np.zeros(shape=(BATCH_SIZE* n_crops, c, h, w))\n",
    "            images2[:bs*n_crops, :c, :h, :w] = images\n",
    "            images = images2\n",
    "\n",
    "        infer_request = request_queue.get_idle_request()\n",
    "        # print(infer_request.request)\n",
    "        # Infer async\n",
    "\n",
    "        infer_request.start_async({input_blob: images}, bs, target)\n",
    "        \n",
    "        # res = res[out_blob]\n",
    "        # res = res.reshape(BATCH_SIZE, n_crops,-1)\n",
    "        # #print(res)\n",
    "        # res = np.mean(res, axis=1)\n",
    "        # if bs != BATCH_SIZE:\n",
    "        #     print(res.shape)\n",
    "        #     res = res[:bs, :res.shape[1]]\n",
    "        # #print(res)\n",
    "        # pred = torch.cat((pred, torch.from_numpy(res)), 0)\n",
    "        # #print(res.shape)\n",
    "\n",
    "    # wait the latest inference executions\n",
    "    request_queue.wait_all()\n",
    "    for i, queue in enumerate(request_queue.requests):\n",
    "        # print(i, queue)\n",
    "        gt = torch.cat((gt, queue.get_ground_truth()), 0)\n",
    "        pred = torch.cat((pred, queue.get_prediction()), 0)\n",
    "        \n",
    "    print('Elapsed time: %0.2f sec.' % (timeit.default_timer() - now))\n",
    "\n",
    "    AUROCs = compute_AUCs(gt, pred)\n",
    "    AUROC_avg = np.array(AUROCs).mean()\n",
    "    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {:.3f}'.format(CLASS_NAMES[i], AUROCs[i]))\n",
    "\n",
    "def roc_auc_score_FIXED(y_true, y_pred):\n",
    "    if len(np.unique(y_true)) == 1:\n",
    "        return accuracy_score(y_true, np.rint(y_pred))\n",
    "    return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        \n",
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score_FIXED(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_async()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
